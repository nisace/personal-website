<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-09-28">
<meta name="description" content="A deep dive into variational autoencoders.">

<title>Variational autoencoders – Nisace’s website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Nisace’s website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#why-variational-autoencoders" id="toc-why-variational-autoencoders" class="nav-link" data-scroll-target="#why-variational-autoencoders">Why variational autoencoders?</a></li>
  </ul></li>
  <li><a href="#formalization" id="toc-formalization" class="nav-link" data-scroll-target="#formalization">Formalization</a>
  <ul class="collapse">
  <li><a href="#problem-setting" id="toc-problem-setting" class="nav-link" data-scroll-target="#problem-setting">Problem setting</a></li>
  <li><a href="#goal" id="toc-goal" class="nav-link" data-scroll-target="#goal">Goal</a></li>
  <li><a href="#problem" id="toc-problem" class="nav-link" data-scroll-target="#problem">Problem</a></li>
  <li><a href="#strategy" id="toc-strategy" class="nav-link" data-scroll-target="#strategy">Strategy</a></li>
  </ul></li>
  <li><a href="#find-tractable-objective" id="toc-find-tractable-objective" class="nav-link" data-scroll-target="#find-tractable-objective">Find tractable objective</a>
  <ul class="collapse">
  <li><a href="#steps" id="toc-steps" class="nav-link" data-scroll-target="#steps">Steps</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#rearrange-klq_phizx-pzx-asklq_phizx-pzx-klq_phizx-pz---e_q_phizxlbrack-log-pxzrbrack-log-px" id="toc-rearrange-klq_phizx-pzx-asklq_phizx-pzx-klq_phizx-pz---e_q_phizxlbrack-log-pxzrbrack-log-px" class="nav-link" data-scroll-target="#rearrange-klq_phizx-pzx-asklq_phizx-pzx-klq_phizx-pz---e_q_phizxlbrack-log-pxzrbrack-log-px">Rearrange <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> as<span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x)) = KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span></a></li>
  <li><a href="#equivalent-objective" id="toc-equivalent-objective" class="nav-link" data-scroll-target="#equivalent-objective">Equivalent objective</a></li>
  <li><a href="#focus-on-the-tractable-terms-and-define-a-new-objective" id="toc-focus-on-the-tractable-terms-and-define-a-new-objective" class="nav-link" data-scroll-target="#focus-on-the-tractable-terms-and-define-a-new-objective">Focus on the tractable terms and define a new objective</a></li>
  </ul></li>
  <li><a href="#interpretation-of-the-tractable-objective" id="toc-interpretation-of-the-tractable-objective" class="nav-link" data-scroll-target="#interpretation-of-the-tractable-objective">Interpretation of the tractable objective</a></li>
  <li><a href="#maximize-elbo-e_q_phizxlbrack-log-p_thetaxzrbrack---klq_phizx-p_thetaz" id="toc-maximize-elbo-e_q_phizxlbrack-log-p_thetaxzrbrack---klq_phizx-p_thetaz" class="nav-link" data-scroll-target="#maximize-elbo-e_q_phizxlbrack-log-p_thetaxzrbrack---klq_phizx-p_thetaz">Maximize <span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ \ p_{\theta}(x|z)\rbrack - \ KL(q_{\phi}(z|x)\ ||\ \ p_{\theta}(z))\)</span></a>
  <ul class="collapse">
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  <li><a href="#gradient-with-respect-to-theta" id="toc-gradient-with-respect-to-theta" class="nav-link" data-scroll-target="#gradient-with-respect-to-theta">Gradient with respect to <span class="math inline">\(\theta\)</span></a></li>
  <li><a href="#gradient-with-respect-to-phi" id="toc-gradient-with-respect-to-phi" class="nav-link" data-scroll-target="#gradient-with-respect-to-phi">Gradient with respect to <span class="math inline">\(\phi\)</span></a>
  <ul class="collapse">
  <li><a href="#expectation-part" id="toc-expectation-part" class="nav-link" data-scroll-target="#expectation-part">Expectation part</a></li>
  <li><a href="#kullback-leibler-divergence-part" id="toc-kullback-leibler-divergence-part" class="nav-link" data-scroll-target="#kullback-leibler-divergence-part">Kullback-Leibler divergence part</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#origin-of-the-elbo-name" id="toc-origin-of-the-elbo-name" class="nav-link" data-scroll-target="#origin-of-the-elbo-name">Origin of the <span class="math inline">\(ELBO\)</span> name</a></li>
  <li><a href="#practical-application" id="toc-practical-application" class="nav-link" data-scroll-target="#practical-application">Practical application</a>
  <ul class="collapse">
  <li><a href="#derive-the-gradient-of-the-kullback-leibler-divergence-part" id="toc-derive-the-gradient-of-the-kullback-leibler-divergence-part" class="nav-link" data-scroll-target="#derive-the-gradient-of-the-kullback-leibler-divergence-part">Derive the gradient of the Kullback-Leibler divergence part</a>
  <ul class="collapse">
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2">Summary</a></li>
  <li><a href="#details" id="toc-details" class="nav-link" data-scroll-target="#details">Details</a></li>
  </ul></li>
  <li><a href="#define-the-loss-function" id="toc-define-the-loss-function" class="nav-link" data-scroll-target="#define-the-loss-function">Define the loss function</a></li>
  <li><a href="#consequences-of-minimizing-the-reversed-kullback-leibler-divergence-between-the-posteriors" id="toc-consequences-of-minimizing-the-reversed-kullback-leibler-divergence-between-the-posteriors" class="nav-link" data-scroll-target="#consequences-of-minimizing-the-reversed-kullback-leibler-divergence-between-the-posteriors">Consequences of minimizing the reversed Kullback-Leibler divergence between the posteriors</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#initial-intractable-objective" id="toc-initial-intractable-objective" class="nav-link" data-scroll-target="#initial-intractable-objective">Initial intractable objective</a></li>
  <li><a href="#approximate-tractable-objective" id="toc-approximate-tractable-objective" class="nav-link" data-scroll-target="#approximate-tractable-objective">Approximate tractable objective</a></li>
  <li><a href="#maximize-elbo-with-the-reparameterization-trick" id="toc-maximize-elbo-with-the-reparameterization-trick" class="nav-link" data-scroll-target="#maximize-elbo-with-the-reparameterization-trick">Maximize <span class="math inline">\(ELBO\)</span> with the reparameterization trick</a></li>
  </ul></li>
  <li><a href="#glossary" id="toc-glossary" class="nav-link" data-scroll-target="#glossary">Glossary</a>
  <ul class="collapse">
  <li><a href="#variational-distribution" id="toc-variational-distribution" class="nav-link" data-scroll-target="#variational-distribution">Variational distribution</a></li>
  <li><a href="#evidence-lower-bound-elbo-or-variational-lower-bound" id="toc-evidence-lower-bound-elbo-or-variational-lower-bound" class="nav-link" data-scroll-target="#evidence-lower-bound-elbo-or-variational-lower-bound">Evidence Lower Bound (ELBO) or variational lower bound</a></li>
  <li><a href="#reparameterization-gradients" id="toc-reparameterization-gradients" class="nav-link" data-scroll-target="#reparameterization-gradients">Reparameterization gradients</a></li>
  </ul></li>
  <li><a href="#ressources" id="toc-ressources" class="nav-link" data-scroll-target="#ressources">Ressources</a>
  <ul class="collapse">
  <li><a href="#variational-autoencoders" id="toc-variational-autoencoders" class="nav-link" data-scroll-target="#variational-autoencoders">Variational autoencoders</a></li>
  <li><a href="#autoencoders-vs-variational-autoencoders" id="toc-autoencoders-vs-variational-autoencoders" class="nav-link" data-scroll-target="#autoencoders-vs-variational-autoencoders">Autoencoders vs variational autoencoders</a></li>
  <li><a href="#elbo" id="toc-elbo" class="nav-link" data-scroll-target="#elbo">ELBO</a>
  <ul class="collapse">
  <li><a href="#definition" id="toc-definition" class="nav-link" data-scroll-target="#definition">Definition</a></li>
  <li><a href="#gradient" id="toc-gradient" class="nav-link" data-scroll-target="#gradient">Gradient</a></li>
  </ul></li>
  <li><a href="#kullback-leibler-divergence" id="toc-kullback-leibler-divergence" class="nav-link" data-scroll-target="#kullback-leibler-divergence">Kullback Leibler divergence</a></li>
  <li><a href="#reparameterization-trick" id="toc-reparameterization-trick" class="nav-link" data-scroll-target="#reparameterization-trick">Reparameterization trick</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Variational autoencoders</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Machine Learning</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>A deep dive into variational autoencoders.</p>
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 28, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This document dives into <a href="https://arxiv.org/abs/1312.6114">variational autoencoders (VAE)</a>.</p>
<section id="why-variational-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="why-variational-autoencoders">Why variational autoencoders?</h2>
<p>The first question we can ask is why create variational autoencoders?</p>
<ul>
<li><p>Variational autoencoders are generative models that allow to generate data such as text, images or sounds for instance.</p></li>
<li><p>Unlike autoencoders, variational autoencoders allow interpolation in their latent space.</p>
<ul>
<li><p>This is because autoencoders produce a fixed encoding for a given input while variational autoencoders produce a probability distribution.</p></li>
<li><p>This forces the decoder of a variational autoencoder to learn to decode over continuous regions of the latent space, not only from specific single points as in an autoencoder.</p></li>
<li><p>We can find more information about this in this <a href="https://medium.com/data-science/intuitively-understanding-variational-autoencoders-1bfe67eb5daf">blog post</a>.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="formalization" class="level1">
<h1>Formalization</h1>
<section id="problem-setting" class="level2">
<h2 class="anchored" data-anchor-id="problem-setting">Problem setting</h2>
<ul>
<li><p>We have a dataset of samples of a random variable <span class="math inline">\(x\)</span>.</p></li>
<li><p>We assume it is generated by a random process <span class="math inline">\(p\)</span> and a random variable <span class="math inline">\(z\)</span>.</p></li>
</ul>
</section>
<section id="goal" class="level2">
<h2 class="anchored" data-anchor-id="goal">Goal</h2>
<p>The goal is to perform Bayesian inference, i.e.&nbsp;estimate <span class="math inline">\(p(z|x)\)</span>.</p>
<p>This will allow to build meaningful representations <span class="math inline">\(z\)</span> of <span class="math inline">\(x\)</span>.</p>
<p>These representations can then be used for example to:</p>
<ul>
<li><p>Cluster samples from <span class="math inline">\(x\)</span> based on their representation <span class="math inline">\(z\)</span>.</p></li>
<li><p>Edit samples from <span class="math inline">\(x\)</span> by manipulating their representation <span class="math inline">\(z\)</span>.</p></li>
<li><p>Generate samples <span class="math inline">\(x\)</span> by sampling from the distribution of <span class="math inline">\(z\)</span> which can be chosen to be simple to sample from.</p></li>
</ul>
</section>
<section id="problem" class="level2">
<h2 class="anchored" data-anchor-id="problem">Problem</h2>
<p>One approach could be to</p>
<ul>
<li><p>Choose a simple distribution <span class="math inline">\(p(z)\)</span>.</p></li>
<li><p>Use the Bayes’ rule <span class="math inline">\(p(z|x) = \frac{p(z,\ x)}{p(x)} = \frac{p(x|z)p(z)}{\int_{z}^{}p(x|z)p(z)dz}\)</span> to compute <span class="math inline">\(p(z|x)\)</span>.</p></li>
<li><p>However, <span class="math inline">\(p(x) = \int_{z}^{}p(x|z)p(z)dz\)</span> is usually intractable because:</p>
<ul>
<li><p><span class="math inline">\(p(x|z)\)</span> is unknown.</p></li>
<li><p>We could parameterize it with <span class="math inline">\(p_{\theta}(x|z)\)</span>.</p></li>
<li><p>But even for moderately complicated likelihood functions <span class="math inline">\(p_{\theta}(x|z)\)</span> such as a neural network with a nonlinear hidden layer for example, there is no closed-form solution to the integral <span class="math inline">\(p_{\theta}(x) = \int_{z}^{}p_{\theta}(x|z)p(z)dz\)</span>.</p></li>
<li><p>Also, <span class="math inline">\(z\)</span> usually is in high dimension:</p>
<ul>
<li><p>Integrating over such a high-dimensional space is computationally impossible.</p></li>
<li><p>Monte Carlo estimations are too expensive.</p></li>
</ul></li>
</ul></li>
<li><p>Thus, we cannot compute <span class="math inline">\(p(x)\)</span> which prevents us from computing <span class="math inline">\(p(z|x)\)</span>.</p></li>
</ul>
</section>
<section id="strategy" class="level2">
<h2 class="anchored" data-anchor-id="strategy">Strategy</h2>
<p>Model <span class="math inline">\(p(z|x)\)</span> by a parametric distribution <span class="math inline">\(q_{\phi}(z|x)\)</span> and minimize <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> (see <a href="../../posts/information-theory/index.html#kullback--leibler-divergence">Kullback–Leibler divergence</a>).</p>
<p><span class="math inline">\(q_{\phi}(z|x)\)</span> is sometimes called the <em>variational distribution</em> (see <a href="#glossary">Glossary</a>).</p>
<p>Minimize the reversed <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> and not the forward <span class="math inline">\(KL(p(z|x)\ ||\ q_{\phi}(z|x))\)</span> because <span class="math inline">\(p(z|x)\)</span> is unknown thus, the expectation under <span class="math inline">\(p(z|x)\)</span> cannot be computed.</p>
<p>This results in mode seeking behavior. See:</p>
<ul>
<li><p><a href="../../posts/information-theory/index.html#forward-vs-reversed-kullback-leibler-divergence">Forward vs reversed Kullback-Leibler divergence</a></p></li>
<li><p>and <a href="#consequences-of-minimizing-the-reversed-kullback-leibler-divergence-between-the-posteriors">Consequences of minimizing the reversed Kullback-Leibler divergence between the posteriors</a></p></li>
</ul>
</section>
</section>
<section id="find-tractable-objective" class="level1">
<h1>Find tractable objective</h1>
<section id="steps" class="level2">
<h2 class="anchored" data-anchor-id="steps">Steps</h2>
<p>Here is a summary of the different steps to estimate <span class="math inline">\(q_{\phi}(z|x)\)</span>. The details for each step are given below.</p>
<ul>
<li>The goal is</li>
</ul>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
Minimize <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> with respect to <span class="math inline">\(\phi\)</span>
</div>
<div>
(Objective 1)
</div>
</div>
<ul>
<li><p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> still contains the intractable <span class="math inline">\(p(z|x)\)</span> we are looking for but it can be expressed differently.</p></li>
<li><p>Rearrange <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> as<span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x)) = KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span><br>
(see <a href="#rearrange-klq_phizx-pzx-asklq_phizx-pzx-klq_phizx-pz---e_q_phizxlbrack-log-pxzrbrack-log-px">details below</a>).</p></li>
<li><p>This gives the <a href="#equivalent-objective">equivalent objective</a></p></li>
</ul>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
Minimize <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack\)</span> with respect to <span class="math inline">\(\phi\)</span>
</div>
<div>
(Objective 2)
</div>
</div>
<ul>
<li><p>However, <span class="math inline">\(p(x|z)\)</span> is unknown.</p></li>
<li><p>We can parameterize it with <span class="math inline">\(p_{\theta}(x|z)\)</span> and learn it from data.</p></li>
<li><p>Focus on the tractable terms and define a new objective (see <a href="#focus-on-the-tractable-terms-and-define-a-new-objective">details below</a>).</p></li>
</ul>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
Maximize<span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z)) = log\ p_{\theta}(x) - KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span><br>
with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span>
</div>
<div>
(Objective 3)
</div>
</div>
<ul>
<li><p>(Objective 3) is not equivalent to (Objective 1) and (Objective 2), it is an approximation.</p></li>
<li><p>(Objective 3) <span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z))\)</span> is called the ELBO (see <a href="#origin-of-the-elbo-name">Origin of the ELBO name</a>).</p></li>
</ul>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<ul>
<li>The initial objective was</li>
</ul>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
Minimize <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> with respect to <span class="math inline">\(\phi\)</span>
</div>
<div>
(Objective 1)
</div>
</div>
<ul>
<li>It is intractable thus, an approximate objective is used instead</li>
</ul>
<p>Maximize <span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z))\)</span> with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span> (Objective 3)</p>
</section>
<section id="rearrange-klq_phizx-pzx-asklq_phizx-pzx-klq_phizx-pz---e_q_phizxlbrack-log-pxzrbrack-log-px" class="level2">
<h2 class="anchored" data-anchor-id="rearrange-klq_phizx-pzx-asklq_phizx-pzx-klq_phizx-pz---e_q_phizxlbrack-log-pxzrbrack-log-px">Rearrange <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> as<span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x)) = KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span></h2>
<ul>
<li><p>We ideally want to minimize <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> with respect to <span class="math inline">\(\phi\)</span>.</p></li>
<li><p>But as seen above, the true posterior <span class="math inline">\(p(z|x)\)</span> is unknown and intractable.</p></li>
<li><p>Using the Bayes’ rule, <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> can be rewritten in terms of</p>
<ul>
<li><p><span class="math inline">\(p(x|z)\)</span></p></li>
<li><p><span class="math inline">\(p(x)\)</span></p></li>
<li><p><span class="math inline">\(p(z)\)</span></p></li>
</ul></li>
<li><p>As seen above <span class="math inline">\(p(x)\)</span> is intractable but</p>
<ul>
<li><p><span class="math inline">\(p(z)\)</span> can be chosen to be a simple distribution.</p></li>
<li><p><span class="math inline">\(p(x|z)\)</span> is unknown but it could be latter parameterized with <span class="math inline">\(p_{\theta}(x|z)\)</span>.</p></li>
</ul></li>
<li><p>The idea is to rewrite <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> in terms of <span class="math inline">\(p(x|z)\)</span>, <span class="math inline">\(p(x)\)</span> and <span class="math inline">\(p(z)\)</span> and to focus on the tractable terms.</p></li>
<li><p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> can be rewritten as</p></li>
</ul>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x)) = KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span></p>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span></p>
<p><span class="math inline">\(= \ E_{q_{\phi}(z|x)}\lbrack log\ \frac{q_{\phi}(z|x)}{p(z|x)}\rbrack\)</span></p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\(= \ E_{q_{\phi}(z|x)}\lbrack log\ \frac{q_{\phi}(z|x)\ p(x)}{p(x|z)p(z)}\rbrack\)</span>
</div>
<div>
(by Bayes’ rule <span class="math inline">\(p(z|x)p(x) = p(x|z)p(z)\)</span>)
</div>
</div>
<p><span class="math inline">\(= \ E_{q_{\phi}(z|x)}\lbrack log\ \frac{q_{\phi}(z|x)}{p(z)} - log\ p(x|z) + log\ p(x)\rbrack\)</span></p>
<p><span class="math inline">\(= \ E_{q_{\phi}(z|x)}\lbrack log\ \frac{q_{\phi}(z|x)}{p(z)}\rbrack - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span></p>
<p><span class="math inline">\(= KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span></p>
</section>
<section id="equivalent-objective" class="level2">
<h2 class="anchored" data-anchor-id="equivalent-objective">Equivalent objective</h2>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x)) = KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack + log\ p(x)\)</span></p>
<ul>
<li><span class="math inline">\(p(x)\)</span> does not depend on <span class="math inline">\(\phi\)</span>, thus minimizing <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span> with respect to <span class="math inline">\(\phi\)</span> is equivalent to maximizing <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack\)</span>.</li>
</ul>
</section>
<section id="focus-on-the-tractable-terms-and-define-a-new-objective" class="level2">
<h2 class="anchored" data-anchor-id="focus-on-the-tractable-terms-and-define-a-new-objective">Focus on the tractable terms and define a new objective</h2>
<ul>
<li><p><span class="math inline">\(p(x|z)\)</span> is unknown.</p></li>
<li><p>We can parameterize it with <span class="math inline">\(p_{\theta}(x|z)\)</span> and learn it from data.</p></li>
<li><p>We now have two sets of parameters <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span> to learn.</p></li>
<li><p>Our new objective is to minimize</p></li>
</ul>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x)) = KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack + log\ p_{\theta}(x)\)</span></p>
<p>with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span>.</p>
<ul>
<li><p>Notice that the equivalence mentioned above is only true for fixed parameters <span class="math inline">\(\theta\)</span>.</p>
<ul>
<li><p>When <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span> are learned jointly, <span class="math inline">\(log\ p_{\theta}(x)\)</span> is no longer constant.</p></li>
<li><p>When the values of <span class="math inline">\(\theta\)</span> change, the target for <span class="math inline">\(q_{\phi}(z|x)\)</span> in <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span> changes too.</p></li>
<li><p>Thus, maximizing <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span> with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span> is not equivalent to minimizing <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span> with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span>.</p></li>
</ul></li>
<li><p>We focus anyway on maximizing <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z)) - E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span> because these are the only tractable terms.</p></li>
<li><p>We can rearrange the expression above as</p></li>
</ul>
<p><span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z)) = log\ p_{\theta}(x) - KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span></p>
</section>
</section>
<section id="interpretation-of-the-tractable-objective" class="level1">
<h1>Interpretation of the tractable objective</h1>
<p>The new objective is</p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
Maximize
</div>
<div>
(Objective 3)
</div>
</div>
<p><span class="math inline">\(ELBO\)</span><br>
</p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\(= log\ p_{\theta}(x) - KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span>
</div>
<div>
(1)
</div>
</div>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\(= E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z))\)</span>
</div>
<div>
(2)
</div>
</div>
<p>with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span></p>
<p>We can see two types of terms in the expression above</p>
<ul>
<li><p><span class="math inline">\(q_{\phi}\)</span>: the encoder which maps the observed data <span class="math inline">\(x\)</span> to its representation <span class="math inline">\(z\)</span>.</p></li>
<li><p><span class="math inline">\(p_{\theta}\)</span>: the decoder which reconstruct <span class="math inline">\(x\)</span> from representations <span class="math inline">\(z\)</span>.</p></li>
</ul>
<p>Maximizing the expression above can be interpreted as</p>
<ul>
<li><p>Term (1)</p>
<ul>
<li><p>The decoder <span class="math inline">\(p_{\theta}\)</span> is trained to maximize the marginal log likelihood of the data <span class="math inline">\(x\)</span>.</p></li>
<li><p>The encoder <span class="math inline">\(q_{\phi}\)</span> is trained to approximate the posterior <span class="math inline">\(p_{\theta}(z|x)\  \propto \ p_{\theta}(x|z)\ p(z)\)</span> implied by the decoder <span class="math inline">\(p_{\theta}(x|z)\)</span> and the prior <span class="math inline">\(p(z)\)</span>.</p></li>
</ul></li>
<li><p>Term (2)</p>
<ul>
<li><p>The decoder <span class="math inline">\(p_{\theta}\)</span> is trained to maximize the log likelihood of the data <span class="math inline">\(x\)</span> given its representation <span class="math inline">\(z\)</span> built by the encoder <span class="math inline">\(q_{\phi}\)</span>.</p></li>
<li><p>The encoder <span class="math inline">\(q_{\phi}\)</span> is trained to produce representations <span class="math inline">\(z\)</span> close to the prior <span class="math inline">\(p(z)\)</span> and consistent with the likelihood of the decoder <span class="math inline">\(p_{\theta}(x|z)\)</span>.</p></li>
<li><p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z))\)</span></p>
<ul>
<li><p>It can be seen as a regularization term that forces the estimated posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> to be close to the chosen prior <span class="math inline">\(p(z)\)</span>.</p></li>
<li><p>This regularization is applied to each data sample <span class="math inline">\(x\)</span>. Thus, it encourages the posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> to be the same for all data samples <span class="math inline">\(x\)</span>, i.e.&nbsp;it encourages the posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> to not convey any information unique to the individual data sample <span class="math inline">\(x\)</span>.</p></li>
<li><p>In this way, the <span class="math inline">\(KL\)</span> term and the likelihood term are conflicting.</p></li>
</ul></li>
</ul></li>
</ul>
<p>The <span class="math inline">\(ELBO\)</span> enforces a mutual consistency:</p>
<ul>
<li><p>The encoder reflects the latent structure suggested by the decoder,</p></li>
<li><p>And the decoder adapts to the latent codes produced by the encoder, all while fitting the observed data.</p></li>
</ul>
</section>
<section id="maximize-elbo-e_q_phizxlbrack-log-p_thetaxzrbrack---klq_phizx-p_thetaz" class="level1">
<h1>Maximize <span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ \ p_{\theta}(x|z)\rbrack - \ KL(q_{\phi}(z|x)\ ||\ \ p_{\theta}(z))\)</span></h1>
<p>Now that the objective has been defined, this section focuses on how to address it. Again, the summary gives an overview of the different steps and the details for each step are given below.</p>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">Summary</h2>
<p>The objective is to maximize the <span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z))\)</span>.</p>
<ul>
<li><p><a href="#gradient-with-respect-to-theta">Gradients with respect to</a> <span class="math inline">\(\theta\)</span> (for a single sample <span class="math inline">\(x\)</span>)</p>
<ul>
<li><span class="math inline">\(\nabla_{\theta}ELBO \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\theta}log\ p_{\theta}(x|z_{i})\rbrack\)</span> with <span class="math inline">\(z_{i} \sim q_{\phi}(z|x)\)</span></li>
</ul></li>
<li><p><a href="#gradient-with-respect-to-phi">Gradient with respect to</a><span class="math inline">\(\ \phi\)</span> (for a single sample <span class="math inline">\(x\)</span>)</p>
<ul>
<li><a href="#expectation-part">Expectation part</a></li>
</ul>
<p><span class="math inline">\(\nabla_{\phi}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon_{i})))\)</span> with <span class="math inline">\(\varepsilon_{i} \sim q(\varepsilon)\)</span></p></li>
<li><p>Kullback-Leibler divergence part</p>
<p><span class="math inline">\(p(z)\)</span> and <span class="math inline">\(q_{\phi}(z|x)\)</span> can be chosen in a way that allows the Kullback-Leibler divergence part to be analytically derived (see <a href="#derive-the-gradient-of-the-kullback-leibler-divergence-part">Kullback-Leibler divergence part</a> in the <a href="#practical-application">Practical application</a> section).</p></li>
<li><p><span class="math inline">\(\nabla_{\phi}ELBO \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon_{i}))) - \nabla_{\phi}KL(q_{\phi}(z|x)\ ||\ p(z))\)</span> with <span class="math inline">\(\varepsilon_{i} \sim q(\varepsilon)\)</span></p></li>
</ul>
</section>
<section id="gradient-with-respect-to-theta" class="level2">
<h2 class="anchored" data-anchor-id="gradient-with-respect-to-theta">Gradient with respect to <span class="math inline">\(\theta\)</span></h2>
<p><span class="math inline">\(\nabla_{\theta}ELBO = \nabla_{\theta}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span></p>
<p><span class="math inline">\(q_{\phi}(z|x)\)</span> does not depend on <span class="math inline">\(\theta\)</span> thus (see <a href="../../posts/expectation-and-derivative/index.html">Expectation and derivative</a>):</p>
<p><span class="math inline">\(\nabla_{\theta}ELBO = E_{q_{\phi}(z|x)}\lbrack\nabla_{\theta}log\ p_{\theta}(x|z)\rbrack\)</span></p>
<p>Which can be estimated with a Monte Carlo estimation of the expectation with the mean:<br>
<span class="math inline">\(\nabla_{\theta}ELBO \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\theta}log\ p_{\theta}(x|z_{i})\rbrack\)</span> with <span class="math inline">\(z_{i} \sim q_{\phi}(z|x)\)</span></p>
</section>
<section id="gradient-with-respect-to-phi" class="level2">
<h2 class="anchored" data-anchor-id="gradient-with-respect-to-phi">Gradient with respect to <span class="math inline">\(\phi\)</span></h2>
<p><span class="math inline">\(\nabla_{\phi}ELBO = \nabla_{\phi}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - \nabla_{\phi}KL(q_{\phi}(z|x)\ ||\ p(z))\)</span></p>
<p>The gradient above contains two terms. Let us treat them separately.</p>
<section id="expectation-part" class="level3">
<h3 class="anchored" data-anchor-id="expectation-part">Expectation part</h3>
<p>The expectation depends on <span class="math inline">\(\phi\)</span>, thus, the gradient cannot be written as <span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack\nabla_{\phi}log\ p_{\theta}(x|z)\rbrack\)</span>.<br>
As explained in <a href="../../posts/expectation-and-derivative/index.html">Expectation and derivative</a>, there are several solutions. Two of them are:</p>
<ul>
<li><p>Use the <a href="../../posts/expectation-and-derivative/index.html#score-function-estimator">score function estimator</a></p></li>
<li><p>Or the <a href="../../posts/expectation-and-derivative/index.html#reparameterization-trick">reparametrization trick</a></p></li>
</ul>
<p>The reparameterization is used because is offers a lower gradient variance than the score function estimator and because <span class="math inline">\(p_{\theta}(x|z)\)</span> is differentiable.</p>
<section id="application-of-the-reparameterization-trick" class="level4">
<h4 class="anchored" data-anchor-id="application-of-the-reparameterization-trick">Application of the reparameterization trick</h4>
<p><span class="math inline">\(\nabla_{\phi}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span></p>
<p>We can</p>
<ul>
<li><p>Express our random variable <span class="math inline">\(z\)</span></p>
<ul>
<li><span class="math inline">\(z \sim q_{\phi}(z|x)\)</span></li>
</ul></li>
<li><p>As a function <span class="math inline">\(g_{\phi}\)</span> of another random variable <span class="math inline">\(\varepsilon\)</span></p>
<ul>
<li><span class="math inline">\(z = g_{\phi}(\varepsilon)\)</span> with <span class="math inline">\(\varepsilon \sim n(\varepsilon)\)</span></li>
</ul></li>
</ul>
<p>Then the <a href="../../posts/expectation-and-derivative/index.html#law-of-the-unconscious-statistician-lotus">Law of the Unconscious Statistician (LOTUS)</a> tells us that</p>
<ul>
<li><p>The expectation of <span class="math inline">\(z\)</span> can be computed with the distribution of <span class="math inline">\(\varepsilon\)</span></p>
<ul>
<li><span class="math inline">\(\nabla_{\phi}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span></li>
</ul>
<p><span class="math inline">\(= \nabla_{\phi}E_{n(\varepsilon)}\lbrack log\ p_{\theta}(x|g_{\phi}(\varepsilon))\rbrack\)</span></p></li>
</ul>
<p>With this new formulation, the distribution no longer depends on <span class="math inline">\(\phi\)</span>. Thus we are in a <a href="../../posts/expectation-and-derivative/index.html#fixed-distribution">Fixed distribution</a> setting.</p>
<p>Thus,</p>
<p><span class="math inline">\(\nabla_{\phi}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span></p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\(= \nabla_{\phi}E_{n(\varepsilon)}\lbrack log\ p_{\theta}(x|g_{\phi}(\varepsilon))\rbrack\)</span>
</div>
<div>
(<a href="../../posts/expectation-and-derivative/index.html#law-of-the-unconscious-statistician-lotus">LOTUS</a>)
</div>
</div>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\({= E}_{n(\varepsilon)}\lbrack\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon)))\rbrack\)</span>
</div>
<div>
(<span class="math inline">\(n\)</span> does not depend on <span class="math inline">\(\phi\)</span>)
</div>
</div>
<p>which can be estimated with Monte Carlo</p>
<p><span class="math inline">\(\nabla_{\phi}E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack\)</span></p>
<p><span class="math inline">\(\simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon_{i})))\)</span> with <span class="math inline">\(\varepsilon_{i} \sim q(\varepsilon)\)</span></p>
</section>
</section>
<section id="kullback-leibler-divergence-part" class="level3">
<h3 class="anchored" data-anchor-id="kullback-leibler-divergence-part">Kullback-Leibler divergence part</h3>
<p><span class="math inline">\(p(z)\)</span> and <span class="math inline">\(q_{\phi}(z|x)\)</span> can be chosen in a way that allows the Kullback-Leibler divergence part to be analytically derived (see <a href="#derive-the-gradient-of-the-kullback-leibler-divergence-part">Kullback-Leibler divergence part</a> in the <a href="#practical-application">Practical application</a> section).</p>
</section>
</section>
</section>
<section id="origin-of-the-elbo-name" class="level1">
<h1>Origin of the <span class="math inline">\(ELBO\)</span> name</h1>
<ul>
<li><p><span class="math inline">\(ELBO = log\ p_{\theta}(x) - KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span>.</p></li>
<li><p>Thus, <span class="math inline">\(ELBO \leq log\ p_{\theta}(x)\)</span> because the <span class="math inline">\(KL\)</span> term is always positive.</p></li>
<li><p><span class="math inline">\(log\ p_{\theta}(x)\)</span> is the <span class="math inline">\(\log\)</span> of the evidence of the data.</p></li>
<li><p>Hence the name <em>Evidence Lower Bound</em>.</p></li>
</ul>
</section>
<section id="practical-application" class="level1">
<h1>Practical application</h1>
<section id="derive-the-gradient-of-the-kullback-leibler-divergence-part" class="level2">
<h2 class="anchored" data-anchor-id="derive-the-gradient-of-the-kullback-leibler-divergence-part">Derive the gradient of the Kullback-Leibler divergence part</h2>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>As shown in the <a href="#details">Details</a> section below, the Kullback-Leibler divergence term in the <span class="math inline">\(ELBO\)</span> can be derived analytically for well chosen <span class="math inline">\(p(z)\)</span> and <span class="math inline">\(q_{\phi}(z|x)\)</span> distributions.</p>
<p>More specifically,</p>
<ul>
<li><p>For <span class="math inline">\(p(z) = N(z;0,\ I)\)</span> and</p>
<p><span class="math inline">\(\nabla_{\phi}KL(q_{\phi}(z|x)\ ||\ p(z)) = \nabla_{\phi}\frac{1}{2}\sum_{i = 1}^{k}(\mu_{i}^{2} + \sigma_{i}^{2} - log\ \sigma_{i}^{2} - 1)\)</span></p></li>
</ul>
<p>And thus,</p>
<ul>
<li><span class="math inline">\(\nabla_{\phi}ELBO \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon_{i}))) + \nabla_{\phi}\frac{1}{2}\sum_{i = 1}^{k}(\mu_{i}^{2} + \sigma_{i}^{2} - log\ \sigma_{i}^{2} - 1)\)</span> with <span class="math inline">\(\varepsilon_{i} \sim q(\varepsilon)\)</span></li>
</ul>
</section>
<section id="details" class="level3">
<h3 class="anchored" data-anchor-id="details">Details</h3>
<p>The Kullback-Leibler divergence term is <span class="math inline">\(\nabla_{\phi}KL(q_{\phi}(z|x)\ ||\ p(z))\)</span>.</p>
<p>Let us choose both distributions <span class="math inline">\(q_{\phi}(z|x)\)</span> and <span class="math inline">\(p(z)\)</span> to be multivariate gaussian distributions of dimension <span class="math inline">\(k\)</span>.</p>
<ul>
<li><p><span class="math inline">\(p(z) = N(z;0,\ I)\)</span></p></li>
<li><p><span class="math inline">\(q_{\phi}(z|x) = N(z;\mu,\Sigma)\)</span></p></li>
<li><p>The probability density distribution for a multivariate gaussian is</p></li>
</ul>
<p><span class="math inline">\(N(x;\mu,\Sigma) = {(2\pi)}^{- k/2}{det(\Sigma)}^{- 1/2}e^{- \frac{1}{2}{(x - \mu)}^{T}\Sigma^{- 1}(x - \mu)}\)</span></p>
<p><span class="math inline">\(log\ N(x;\mu,\Sigma) = - \frac{1}{2}\lbrack{(x - \mu)}^{T}\Sigma^{- 1}(x - \mu) + k\ log(2\pi) + log\ det(\Sigma))\)</span></p>
<ul>
<li>Thus, for <span class="math inline">\(p(z)\)</span> and <span class="math inline">\(q_{\phi}(z|x)\)</span>, we have:</li>
</ul>
<p><span class="math inline">\(\log{\ q}_{\phi}(z|x) = - \frac{1}{2}\lbrack{(z - \mu)}^{T}\Sigma^{- 1}(z - \mu) + k\ log(2\pi) + log\ det(\Sigma))\)</span></p>
<p><span class="math inline">\(log\ p(z) = - \frac{1}{2}\lbrack z^{T}z + k\ log(2\pi)\rbrack\)</span></p>
<ul>
<li>Which gives</li>
</ul>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z))\)</span></p>
<p><span class="math inline">\(= E_{q_{\phi}(z|x)}\lbrack log\ q_{\phi}(z|x) - log\ p(z)\rbrack\)</span></p>
<p><span class="math inline">\(= - \frac{1}{2}E_{q_{\phi}(z|x)}\lbrack{(z - \mu)}^{T}\Sigma^{- 1}(z - \mu) + k\ log(2\pi) + log\ det(\Sigma)) - z^{T}z - k\ log(2\pi)\rbrack\)</span></p>
<p><span class="math inline">\(= \frac{1}{2}E_{q_{\phi}(z|x)}\lbrack z^{T}z\  - {(z - \mu)}^{T}\Sigma^{- 1}(z - \mu)\rbrack - \frac{1}{2}log\ det(\Sigma))\)</span></p>
<ul>
<li>Let us first consider <span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack{(z - \mu)}^{T}\Sigma^{- 1}(z - \mu)\rbrack\)</span></li>
</ul>
<p><span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack{(z - \mu)}^{T}\Sigma^{- 1}(z - \mu)\rbrack\)</span></p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\(= tr(E_{q_{\phi}(z|x)}\lbrack{(z - \mu)}^{T}\Sigma^{- 1}(z - \mu)\rbrack)\)</span>
</div>
<div>
(because <span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack{(z - \mu)}^{T}\Sigma^{- 1}(z - \mu)\rbrack\)</span> is a scalar)
</div>
</div>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
<span class="math inline">\(= tr(\Sigma^{- 1}E_{q_{\phi}(z|x)}\lbrack(z - \mu){(z - \mu)}^{T}\rbrack)\)</span>
</div>
<div>
(by the <a href="https://en.wikipedia.org/wiki/Trace_(linear_algebra)#Cyclic_property">cyclic property of the trace</a>)
</div>
</div>
<p><span class="math inline">\(= tr(\Sigma^{- 1}\Sigma\rbrack)\)</span></p>
<p><span class="math inline">\(= tr(I)\)</span></p>
<p><span class="math inline">\(= k\)</span></p>
<ul>
<li>Let us now consider <span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack z^{T}z\rbrack\)</span></li>
</ul>
<p><span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack z^{T}z\rbrack\)</span></p>
<p><span class="math inline">\(= E_{q_{\phi}(z|x)}\lbrack{tr(z}^{T}z)\rbrack)\)</span></p>
<p><span class="math inline">\(= tr(E_{q_{\phi}(z|x)}\lbrack zz^{T}\rbrack)\)</span></p>
<p>If we write <span class="math inline">\(z = \mu + (z - \mu)\)</span></p>
<p><span class="math inline">\({tr(E}_{q_{\phi}(z|x)}\lbrack zz^{T}\rbrack)\)</span></p>
<p><span class="math inline">\(= tr(E_{q_{\phi}(z|x)}\lbrack(\mu + (z - \mu)){(\mu + (z - \mu))}^{T}\rbrack)\)</span></p>
<p><span class="math inline">\(= tr(E_{q_{\phi}(z|x)}\lbrack\mu\mu^{T} + (z - \mu){(z - \mu)}^{T} + \mu{(z - \mu)}^{T} + (z - \mu)\mu\rbrack)\)</span></p>
<p><span class="math inline">\(= tr(E_{q_{\phi}(z|x)}\lbrack\mu\mu^{T} + (z - \mu){(z - \mu)}^{T}\rbrack)\)</span> (because <span class="math inline">\(E_{q_{\phi}(z|x)}\lbrack z - \mu\rbrack = 0\)</span>)</p>
<p><span class="math inline">\(= tr(\mu\mu^{T} + \Sigma)\)</span></p>
<p><span class="math inline">\(= \mu\mu^{T} + tr(\Sigma)\)</span></p>
<ul>
<li>Finally, we have</li>
</ul>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z)) = \frac{1}{2}(\mu\mu^{T} + tr(\Sigma) - k - log\ det(\Sigma))\)</span></p>
<ul>
<li>If we choose <span class="math inline">\(\Sigma = diag(\sigma_{1}^{2},\ \sigma_{2}^{2},\ ...,\ \sigma_{k}^{2})\)</span></li>
</ul>
<p><span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z))\)</span></p>
<p><span class="math inline">\(= \frac{1}{2}(\mu\mu^{T} + tr(\Sigma) - k - log\ det(\Sigma))\)</span></p>
<p><span class="math inline">\(= \frac{1}{2}(\mu\mu^{T} + \sum_{i = 1}^{k}\sigma_{i}^{2} - k - \sum_{i = 1}^{k}log\ \sigma_{i}^{2})\)</span></p>
<p><span class="math inline">\(=\)</span><span class="math inline">\(\frac{1}{2}\sum_{i = 1}^{k}(\mu_{i}^{2} + \sigma_{i}^{2} - log\ \sigma_{i}^{2} - 1)\)</span></p>
</section>
</section>
<section id="define-the-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="define-the-loss-function">Define the loss function</h2>
<p>As seen above, the final objective is to maximize the <span class="math inline">\(ELBO\)</span> which has the following gradients with respect to <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>.</p>
<ul>
<li><p><span class="math inline">\(\nabla_{\theta}ELBO \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\theta}log\ p_{\theta}(x|z_{i})\rbrack\)</span> with <span class="math inline">\(z_{i} \sim q_{\phi}(z|x)\)</span></p></li>
<li><p><span class="math inline">\(\nabla_{\phi}ELBO \simeq \frac{1}{N}\sum_{i = 1}^{N}\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon_{i}))) - \nabla_{\phi}KL(q_{\phi}(z|x)\ ||\ p(z))\)</span> with <span class="math inline">\(\varepsilon_{i} \sim q(\varepsilon)\)</span></p></li>
</ul>
<p>The <span class="math inline">\(\nabla_{\phi}KL(q_{\phi}(z|x)\ ||\ p(z))\)</span> is addressed in the <a href="#derive-the-gradient-of-the-kullback-leibler-divergence-part">Derive the gradient of the Kullback-Leibler divergence part</a> section above.</p>
<p>The remaining two terms <span class="math inline">\(\frac{1}{N}\sum_{i = 1}^{N}\nabla_{\theta}log\ p_{\theta}(x|z_{i})\rbrack\)</span> and <span class="math inline">\(\frac{1}{N}\sum_{i = 1}^{N}\nabla_{\phi}(log\ p_{\theta}(x|g_{\phi}(\varepsilon_{i})))\)</span> both involve the log likelihood of the data <span class="math inline">\(x\)</span>.</p>
<p>As explained in <a href="../../posts/likelihood-loss/index.html">Maximum Likelihood Estimation and loss functions</a>, maximizing the likelihood (Maximum Likelihood Estimation or MLE) of the observed data is equivalent to minimizing:</p>
<ul>
<li><p>The cross entropy loss in a supervised classification setting.</p></li>
<li><p>The mean squared error (MSE) in a regression setting and under the assumption of normally distributed errors.</p></li>
</ul>
<p>Thus, depending of the choice of <span class="math inline">\(\ p_{\theta}(x|z)\)</span>, the cross entropy loss (binary cross entropy if there are only 2 classes) or the mean squared error (MSE) can be chosen (but other losses are also possible).</p>
<p>Here is a summary of different possible applications.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 19%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Data type for <span class="math inline">\(x\)</span></th>
<th>Problem type</th>
<th>Decoder outputs</th>
<th>Loss function corresponding to MLE</th>
<th>Example of application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Continuous data</td>
<td>Regression</td>
<td>Predicted value</td>
<td>MSE</td>
<td><p>Images (pixels intensities)</p>
<p>Audio signal</p></td>
</tr>
<tr class="even">
<td>Binary data</td>
<td>Binary classification</td>
<td>Probability</td>
<td>Binary cross entropy</td>
<td>Binary images</td>
</tr>
<tr class="odd">
<td>Discrete data</td>
<td>Classification</td>
<td>Class probabilities</td>
<td>Cross entropy</td>
<td>Text tokens</td>
</tr>
</tbody>
</table>
</section>
<section id="consequences-of-minimizing-the-reversed-kullback-leibler-divergence-between-the-posteriors" class="level2">
<h2 class="anchored" data-anchor-id="consequences-of-minimizing-the-reversed-kullback-leibler-divergence-between-the-posteriors">Consequences of minimizing the reversed Kullback-Leibler divergence between the posteriors</h2>
<p>As explained in <a href="#strategy">Strategy</a>, the original objective is to minimize the reversed Kullback-Leibler divergence between the posteriors <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span>.</p>
<p>This results in mode seeking behavior (see <a href="../../posts/information-theory/index.html#forward-vs-reversed-kullback-leibler-divergence">Forward vs reversed Kullback-Leibler divergence</a> to understand why) and has the following consequences:</p>
<ul>
<li><p>Mode collapse</p>
<ul>
<li><p>If the true posterior <span class="math inline">\(p(z|x)\)</span> is multi-modal, the approximate posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> will tend to pick one mode and ignore the others.</p></li>
<li><p>This can cause loss of diversity in the learned latent space.</p></li>
</ul></li>
<li><p>Overly confident uncertainty estimates</p>
<ul>
<li><p>The approximate posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> puts all its mass at the same mode.</p></li>
<li><p>This makes its certainty large at the chosen mode and thus, overconfident.</p></li>
</ul></li>
</ul>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<section id="initial-intractable-objective" class="level2">
<h2 class="anchored" data-anchor-id="initial-intractable-objective">Initial intractable objective</h2>
<p>Minimize <span class="math inline">\(KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span></p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
with respect to <span class="math inline">\(\phi\)</span>
</div>
<div>
(Objective 1)
</div>
</div>
<ul>
<li>Approximate the true posterior <span class="math inline">\(p(z|x)\)</span> with <span class="math inline">\(q_{\phi}(z|x)\)</span>.</li>
</ul>
</section>
<section id="approximate-tractable-objective" class="level2">
<h2 class="anchored" data-anchor-id="approximate-tractable-objective">Approximate tractable objective</h2>
<p><span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z)) = log\ p_{\theta}(x) - KL(q_{\phi}(z|x)\ ||\ p_{\theta}(z|x))\)</span></p>
<div style="display: flex; justify-content: space-between; margin-bottom: 1em;">
<div>
with respect to <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\theta\)</span>
</div>
<div>
(Objective 3)
</div>
</div>
<p>Interpreted as</p>
<ul>
<li><p>Maximize evidence <span class="math inline">\(p_{\theta}(x)\)</span> while making posteriors <span class="math inline">\(p_{\theta}(z|x)\)</span> and <span class="math inline">\(q_{\phi}(z|x)\)</span> similar.</p></li>
<li><p>Maximize likelihood <span class="math inline">\(p_{\theta}(x|z)\)</span> while making posterior <span class="math inline">\(q_{\phi}(z|x)\)</span> close to the chosen prior <span class="math inline">\(p(z)\)</span>.</p></li>
<li><p>Minimize reconstruction error regularized by <span class="math inline">\(KL\)</span> divergence from chosen prior.</p></li>
</ul>
</section>
<section id="maximize-elbo-with-the-reparameterization-trick" class="level2">
<h2 class="anchored" data-anchor-id="maximize-elbo-with-the-reparameterization-trick">Maximize <span class="math inline">\(ELBO\)</span> with the reparameterization trick</h2>
<p><span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ p_{\theta}(x|z)\rbrack - KL(q_{\phi}(z|x)\ ||\ p(z))\)</span></p>
<p>The gradient with respect to <span class="math inline">\(\phi\)</span> of <span class="math inline">\(E_{q_{\phi}(z|x)}\)</span> term cannot be simply estimated with Monte Carlo estimation. The reparameterization trick is used instead.</p>
</section>
</section>
<section id="glossary" class="level1">
<h1>Glossary</h1>
<section id="variational-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variational-distribution">Variational distribution</h2>
<p><span class="math inline">\(q_{\phi}(z|x)\)</span></p>
</section>
<section id="evidence-lower-bound-elbo-or-variational-lower-bound" class="level2">
<h2 class="anchored" data-anchor-id="evidence-lower-bound-elbo-or-variational-lower-bound">Evidence Lower Bound (ELBO) or variational lower bound</h2>
<p><span class="math inline">\({ELBO = E}_{q_{\phi}(z|x)}\lbrack log\ p(x,\ z) - log\ q_{\phi}(z|x)\rbrack\)</span></p>
<p><span class="math inline">\(ELBO = log\ p(x) - \ KL(q_{\phi}(z|x)\ ||\ p(z|x))\)</span></p>
<p><span class="math inline">\(ELBO \leq log\ p(x) = log\ evidence\)</span></p>
<p><span class="math inline">\(ELBO = E_{q_{\phi}(z|x)}\lbrack log\ p(x|z)\rbrack - \ KL(q_{\phi}(z|x)\ ||\ p(z))\)</span></p>
</section>
<section id="reparameterization-gradients" class="level2">
<h2 class="anchored" data-anchor-id="reparameterization-gradients">Reparameterization gradients</h2>
<p>a.k.a pathwise gradients.</p>
<p>The gradients obtained with the reparameterization trick.</p>
</section>
</section>
<section id="ressources" class="level1">
<h1>Ressources</h1>
<section id="variational-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="variational-autoencoders">Variational autoencoders</h2>
<p><a href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a></p>
<p><a href="https://mbernste.github.io/posts/vae/">https://mbernste.github.io/posts/vae/</a></p>
</section>
<section id="autoencoders-vs-variational-autoencoders" class="level2">
<h2 class="anchored" data-anchor-id="autoencoders-vs-variational-autoencoders">Autoencoders vs variational autoencoders</h2>
<p><a href="https://medium.com/data-science/intuitively-understanding-variational-autoencoders-1bfe67eb5daf">https://medium.com/data-science/intuitively-understanding-variational-autoencoders-1bfe67eb5daf</a></p>
</section>
<section id="elbo" class="level2">
<h2 class="anchored" data-anchor-id="elbo">ELBO</h2>
<section id="definition" class="level3">
<h3 class="anchored" data-anchor-id="definition">Definition</h3>
<p><a href="https://mpatacchiola.github.io/blog/2021/01/25/intro-variational-inference.html">https://mpatacchiola.github.io/blog/2021/01/25/intro-variational-inference.html</a></p>
</section>
<section id="gradient" class="level3">
<h3 class="anchored" data-anchor-id="gradient">Gradient</h3>
<p><a href="https://mpatacchiola.github.io/blog/2021/02/08/intro-variational-inference-2.html">https://mpatacchiola.github.io/blog/2021/02/08/intro-variational-inference-2.html</a></p>
</section>
</section>
<section id="kullback-leibler-divergence" class="level2">
<h2 class="anchored" data-anchor-id="kullback-leibler-divergence">Kullback Leibler divergence</h2>
<p><a href="https://kvfrans.com/deriving-the-kl/">https://kvfrans.com/deriving-the-kl/</a></p>
</section>
<section id="reparameterization-trick" class="level2">
<h2 class="anchored" data-anchor-id="reparameterization-trick">Reparameterization trick</h2>
<p><a href="https://gabrielhuang.gitbooks.io/machine-learning/content/reparametrization-trick.html">https://gabrielhuang.gitbooks.io/machine-learning/content/reparametrization-trick.html</a></p>
<p><a href="https://stillbreeze.github.io/REINFORCE-vs-Reparameterization-trick/">https://stillbreeze.github.io/REINFORCE-vs-Reparameterization-trick/</a></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/nisace\.github\.io\/personal-website\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>